WANDB_API_KEY=b3fb3695850f3bdebfee750ead3ae8230c14ea07
RUN_FILE="jsrl-corl/algorithms/finetune/ray_trainer_4seed.py"

DF=Dockerfile
DOCKER_EXTRAS=-e WANDB_API_KEY=$(WANDB_API_KEY) -it --shm-size=10.24gb --cpus 24 -v ./algorithms/finetune/checkpoints:/workspace/checkpoints -v ./algorithms/finetune/wandb:/workspace/wandb -v .:/workspace/lauren-jsrl-corl

build:
	yes | docker container prune

	docker build \
	-f $(DF) \
	-t lauren-jsrl-corl \
	.

runpen1:
	docker run $(DOCKER_EXTRAS) --gpus device="0" \
	lauren-jsrl-corl python $(RUN_FILE) --env AdroitHandPen-v1 --offline_iterations 1000000 --online_iterations 0 --n_curriculum_stages 10 --env_config '{"reward_type": "dense", "max_episode_steps": 100}' --eval_freq 10000 --tolerance 0.05 --beta 3 --iql_tau 0.8 --checkpoints_path checkpoints --horizon_fn agent_type --normalize False ;
	echo 'extra_herbivore' | sudo python3 move_offline_agent.py --env AdroitHandPen-v1  

runhand1:
	docker run $(DOCKER_EXTRAS) --gpus device="0" \
	lauren-jsrl-corl python $(RUN_FILE) --env AdroitHandDoor-v1 --offline_iterations 1000000 --online_iterations 0 --n_curriculum_stages 10 --env_config '{"reward_type": "dense", "max_episode_steps": 200}' --eval_freq 10000 --tolerance 0.05 --beta 3 --iql_tau 0.8 --checkpoints_path checkpoints --horizon_fn agent_type --normalize False ;
	echo 'extra_herbivore' | sudo python3 move_offline_agent.py --env AdroitHandDoor-v1 

runpen2:
	docker run $(DOCKER_EXTRAS) --gpus device="0" \
	lauren-jsrl-corl python $(RUN_FILE) --env AdroitHandPen-v1 --offline_iterations 1000000 --online_iterations 1000000 --n_curriculum_stages 10 --env_config '{"reward_type": "dense", "max_episode_steps": 100}' --eval_freq 10000 --tolerance 0.05 --beta 3 --iql_tau 0.8 --checkpoints_path checkpoints --horizon_fn agent_type --normalize False  --pretrained_policy_path jsrl-corl/algorithms/finetune/checkpoints/IQL-AdroitHandPen-v1-offline/checkpoint_999999.pt ;

runhand2:
	docker run $(DOCKER_EXTRAS) --gpus device="0" \
	lauren-jsrl-corl python $(RUN_FILE) --env AdroitHandDoor-v1 --offline_iterations 1000000 --online_iterations 1000000 --n_curriculum_stages 10 --env_config '{"reward_type": "dense", "max_episode_steps": 200}' --eval_freq 10000 --tolerance 0.05 --beta 3 --iql_tau 0.8 --checkpoints_path checkpoints --horizon_fn agent_type --normalize False --pretrained_policy_path jsrl-corl/algorithms/finetune/checkpoints/IQL-AdroitHandDoor-v1-offline/checkpoint_999999.pt ;


build_and_run: build runhand1 runpen2 runhand2
